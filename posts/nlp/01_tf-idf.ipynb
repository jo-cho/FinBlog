{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d85d3ce1-edca-4b75-a113-75ce79885195",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"자연어처리: DTM, TF-IDF\"\n",
    "subtitle: \"Document-Term Matrix and Term Frequency-Inverse Document Frequency\"\n",
    "author: \"Cheonghyo Cho\"\n",
    "categories: [natural language processing, tfidf]\n",
    "image: \"img/nlp_dtm.png\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b3133-bb58-4501-94c1-4483537c1d08",
   "metadata": {},
   "source": [
    "문서의 의미를 효과적으로 분석하기 위해서는 단어의 출현 빈도를 수치화하는 것이 중요하다. 이를 위해 사용하는 대표적인 방법으로는 DTM(Document-Term Matrix)와 TF-IDF(Term Frequency-Inverse Document Frequency)가 있다. 이러한 방법들은 문서의 핵심 정보를 추출하고, 자연어 처리 작업에서 문서 간의 유사성을 평가하는 데 유용하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3246dbaf-a934-49fe-9f75-50b0f6143c65",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW)\n",
    "\n",
    "Bag of words는 단어의 등장 순서를 고려하지 않는 빈도수 기반의 단어 표현 방법이다. BoW는 각 단어가 등장한 횟수를 수치화하는 텍스트 표현 방법으로, 주로 어떤 단어가 얼마나 등장했는지를 기준으로 문서의 성격을 판단하는 작업에 쓰인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61bbc44a-36fb-423c-bb21-4eedccdedb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW:\n",
      "[[0 0 0 1 1]\n",
      " [1 0 0 1 0]\n",
      " [0 1 1 0 1]]\n",
      "Vocabulary:\n",
      "{'love': 3, 'programming': 4, 'coding': 0, 'is': 2, 'fun': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 예제 문서\n",
    "documents = [\n",
    "    \"I love programming.\",\n",
    "    \"I love coding.\",\n",
    "    \"Programming is fun.\"\n",
    "]\n",
    "\n",
    "# CountVectorizer를 사용하여 BoW 생성\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# BoW 결과 출력\n",
    "print(\"BoW:\")\n",
    "print(X.toarray())\n",
    "print(\"Vocabulary:\")\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b0429-e6ae-4715-896b-0fb7b997ab9b",
   "metadata": {},
   "source": [
    "## 문서 단어 행렬 (Document-Term Matrix, DTM)\n",
    "\n",
    "문서 단어 행렬(Document-Term Matrix, DTM)은 다수의 문서에서 등장하는 각 단어들의 빈도를 행렬로 표현한 것이다.\n",
    "\n",
    "### DTM의 한계점\n",
    "- DTM에서의 각 행(각 문서 벡터)의 차원은 전체 단어 집합의 크기이다.\n",
    "    - 문서 벡터의 차원은 수만 이상의 차원을 가질 수도 있다.\n",
    "    - 대부분의 값이 0을 가질 수도 있다: 희소 표현(sparse representation)\n",
    "    - 많은 양의 저장 공간과 높은 계산 복잡도를 요구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98a6e11-050d-4bb7-a96c-3fa33dfd09ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Term Matrix (DTM):\n",
      "[[0 0 0 1 1]\n",
      " [1 0 0 1 0]\n",
      " [0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# DTM 예제\n",
    "print(\"Document-Term Matrix (DTM):\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c8dbb9-eda4-4fa4-be67-0e615a933f77",
   "metadata": {},
   "source": [
    "각 문서에는 중요한 단어와 불필요한 단어들이 혼재되어 있다.\n",
    "\n",
    "- 예: 불용어(stopwords)는 빈도수가 높더라도 자연어 처리에 있어 의미를 갖지 못하는 단어이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe79abc-7aa1-4a72-bc8a-41ae0b0b5338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM without stopwords:\n",
      "[[0 0 1 1]\n",
      " [1 0 1 0]\n",
      " [0 1 0 1]]\n",
      "Vocabulary without stopwords:\n",
      "{'love': 2, 'programming': 3, 'coding': 0, 'fun': 1}\n"
     ]
    }
   ],
   "source": [
    "# 불용어(stopwords) 제거 예제\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(\"DTM without stopwords:\")\n",
    "print(X.toarray())\n",
    "print(\"Vocabulary without stopwords:\")\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2a582-7282-4fc5-8816-a5a80d4a8289",
   "metadata": {},
   "source": [
    "## TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "TF-IDF(Term Frequency-Inverse Document Frequency)는 단어의 빈도와 문서 빈도를 사용하여 DTM 내의 각 단어마다 중요한 정도를 가중치로 주는 방법이다.\n",
    "\n",
    "TF-IDF는 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4fdaee-31ed-465f-a729-bf714ff14764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF:\n",
      "[[0.         0.         0.         0.70710678 0.70710678]\n",
      " [0.79596054 0.         0.         0.60534851 0.        ]\n",
      " [0.         0.62276601 0.62276601 0.         0.4736296 ]]\n",
      "TF-IDF Vocabulary:\n",
      "{'love': 3, 'programming': 4, 'coding': 0, 'is': 2, 'fun': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "print(\"TF-IDF:\")\n",
    "print(X_tfidf.toarray())\n",
    "print(\"TF-IDF Vocabulary:\")\n",
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d875ee4-2918-47b0-8352-c64c22e79c68",
   "metadata": {},
   "source": [
    "- tf(d,t): 특정 문서 d에서의 특정 단어 t의 등장 횟수\n",
    "- df(t): 특정 단어 t가 등장한 문서의 수\n",
    "- idf(t): df(t)에 반비례하는 수\n",
    "    - 단, 분모에 1을 더하고 로그를 취한다.\n",
    "    - $\\text{idf}(t) = \\log (\\frac{n}{1+\\text{df}(t)})$\n",
    "    - 총 문서의 수 n이 커질수록, IDF의 값이 기하급수적으로 커지는 것을 방지한다.\n",
    "\n",
    "$$\\text{TF-IDF}(t,d)=\\text{tf}(d,t) \\times \\text{idf}(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad69ee4-0b8b-422b-88b8-33c4cb9d029a",
   "metadata": {},
   "source": [
    "## 참고자료\n",
    "\n",
    "- 딥 러닝을 이용한 자연어 처리 입문(https://wikidocs.net/book/2155"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
