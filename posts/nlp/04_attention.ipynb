{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b45240c0-525b-43b7-a1b3-1e8a8bcb9092",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"ìì—°ì–´ì²˜ë¦¬: ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜\"\n",
    "subtitle: \"Seq2seq and Attention mechanism\"\n",
    "author: \"Cheonghyo Cho\"\n",
    "categories: [natural language processing, attention, seq2seq]\n",
    "image: \"img/nlp_04_10.png\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda637c0-8689-4a50-83a4-a24865fd8889",
   "metadata": {},
   "source": [
    "Attention ë©”ì»¤ë‹ˆì¦˜ì€ ëª¨ë¸ì´ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ê´€ë ¨ ë¶€ë¶„ì— ì„ íƒì ìœ¼ë¡œ ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ í•˜ì—¬ ìì—°ì–´ ì²˜ë¦¬ë¶€í„° ì»´í“¨í„° ë¹„ì „ê¹Œì§€ ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤. Seq2seqê³¼ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•´ ì•Œì•„ë³´ì."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffebbb5-3373-47e9-a888-fee99d11dc32",
   "metadata": {},
   "source": [
    "# Seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bfbd9d-b498-4340-baeb-1b89fef9409a",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_1.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c7b5c-bb2c-4047-a4a9-9b0c7d3bc1f1",
   "metadata": {},
   "source": [
    "seq2seqëŠ” ì…ë ¥ëœ ì‹œí€€ìŠ¤ë¡œë¶€í„° ë‹¤ë¥¸ ë„ë©”ì¸ì˜ ì‹œí€€ìŠ¤ë¥¼ ì¶œë ¥í•˜ëŠ” ëª¨ë¸\n",
    "- ì˜ˆ) ì±—ë´‡, ê¸°ê³„ ë²ˆì—­, ë‚´ìš© ìš”ì•½, STT(Speech to Text) ë“±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87be43-dd79-46f4-9278-00388760f557",
   "metadata": {},
   "source": [
    "seq2seqëŠ” í¬ê²Œ ì¸ì½”ë”ì™€ ë””ì½”ë” ë‘ ê°œì˜ ëª¨ë“ˆë¡œ êµ¬ì„±\n",
    "- ì¸ì½”ë”ëŠ” ì…ë ¥ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥ ë°›ì€ ë’¤\n",
    "- ëª¨ë“  ë‹¨ì–´ ì •ë³´ë“¤ì„ ì••ì¶•í•´ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë§Œë“¦ => ì»¨í…ìŠ¤íŠ¸ ë²¡í„°(context vector)\n",
    "- ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ë””ì½”ë”ë¡œ ì „ì†¡\n",
    "- ë””ì½”ë”ëŠ” ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ë°›ì•„ì„œ ë²ˆì—­ëœ ë‹¨ì–´ë¥¼ í•œ ê°œì”© ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96c9deb-4e10-4559-bc8c-e0c56a2ac032",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_2.png' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c5b7b-18b8-4574-a48b-0bc63718c9f7",
   "metadata": {},
   "source": [
    "- ì…ë ¥ ë¬¸ì¥ì˜ ë‹¨ì–´ í† í° ê°ê°ì€ RNN ì…€ì˜ ê° ì‹œì ì˜ ì…ë ¥\n",
    "- ì¸ì½”ë” RNN ì…€ì˜ ë§ˆì§€ë§‰ ì‹œì  ì€ë‹‰ ìƒíƒœ(ì»¨í…ìŠ¤íŠ¸ ë²¡í„°)ë¥¼ ë””ì½”ë” RNN ì…€ë¡œ ì „ì†¡\n",
    "- ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ëŠ” ë””ì½”ë” RNN ì…€ì˜ ì²«ë²ˆì§¸ ì€ë‹‰ ìƒíƒœì— ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc4eb1-77bb-4f63-9935-502c62151421",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_3.png' width='400'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "098d7803-05a4-4fc9-8725-49620839e609",
   "metadata": {},
   "source": [
    "- í˜„ì¬ ì‹œì  tì—ì„œì˜ ì€ë‹‰ ìƒíƒœëŠ” ê³¼ê±° ì‹œì ì˜ ë™ì¼í•œ RNN ì…€ì—ì„œì˜ ëª¨ë“  ì€ë‹‰ ìƒíƒœì˜ ê°’ë“¤ì˜ ì˜í–¥ì„ ëˆ„ì í•´ì„œ ë°›ì•„ì˜¨ ê°’\r",
    "- \n",
    "ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ëŠ” ì…ë ¥ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´ í† í°ë“¤ì˜ ì •ë³´ë¥¼ ìš”ì•½í•´ì„œ ë‹´ê³  ìˆìŒ\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798e262-94b1-4f05-b184-65f8ae15bfdf",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_4.png' width='200'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60127a-a063-4352-b0b4-b6d0edf4eee0",
   "metadata": {},
   "source": [
    "ë””ì½”ë”ì—ì„œ ê° ì‹œì ì˜ RNN ì…€ì—ì„œ ì¶œë ¥ ë²¡í„°ê°€ ë‚˜ì˜¤ë©´, í•´ë‹¹ ë²¡í„°ëŠ” ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ í†µí•´ ì¶œë ¥ ì‹œí€€ìŠ¤ì˜ ê° ë‹¨ì–´ë³„ í™•ë¥ ê°’ì„ ë°˜í™˜, ë””ì½”ë”ëŠ” ì¶œë ¥ ë‹¨ì–´ë¥¼ ê²°ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908430e-46c9-4745-920a-2777ed1bbfd4",
   "metadata": {},
   "source": [
    "ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ëŠ” ë””ì½”ë”ì˜ ì´ˆê¸° ì€ë‹‰ ìƒíƒœë¡œë§Œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆê³ , ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ë””ì½”ë”ê°€ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë§¤ ì‹œì ë§ˆë‹¤ í•˜ë‚˜ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìœ¼ë©°, \n",
    "\n",
    "ë” ë‚˜ì•„ê°€ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì´ë¼ëŠ” ë°©ë²•ì„ í†µí•´ ì§€ê¸ˆ ì•Œê³ ìˆëŠ” ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë³´ë‹¤ ë”ìš± ë¬¸ë§¥ì„ ë°˜ì˜í•  ìˆ˜ ìˆëŠ” ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ êµ¬í•˜ì—¬ ë§¤ ì‹œì ë§ˆë‹¤ í•˜ë‚˜ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŒ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc23102-72c7-4097-aa12-20014378a3fb",
   "metadata": {},
   "source": [
    "# ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜\n",
    "\n",
    "Attention Mechanism"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d12d3b-9a03-41d5-990f-efabecc3f2fd",
   "metadata": {},
   "source": [
    "**RNNì— ê¸°ë°˜í•œ seq2seq ëª¨ë¸ì˜ ë¬¸ì œ**\n",
    "1. í•˜ë‚˜ì˜ ê³ ì •ëœ í¬ê¸°ì˜ ë²¡í„°ì— ëª¨ë“  ì •ë³´ë¥¼ ì••ì¶• => ì •ë³´ ì†ì‹¤ì´ ë°œìƒ\n",
    "2. RNNì˜ ê³ ì§ˆì ì¸ ë¬¸ì œì¸ ê¸°ìš¸ê¸° ì†Œì‹¤(vanishing gradient) ë¬¸ì œ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc043b7-ad2f-4cab-992f-45d20ba3cf45",
   "metadata": {},
   "source": [
    "**ì–´í…ì…˜ì˜ ì•„ì´ë””ì–´**\n",
    "- ë””ì½”ë”ì—ì„œ ì¶œë ¥ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë§¤ ì‹œì ë§ˆë‹¤, ì¸ì½”ë”ì—ì„œì˜ ì „ì²´ ì…ë ¥ ë¬¸ì¥ì„ ë‹¤ì‹œ í•œ ë²ˆ ì°¸ê³  \n",
    "- ë‹¨, ì „ì²´ ì…ë ¥ ë¬¸ì¥ì„ ì „ë¶€ ë‹¤ ë™ì¼í•œ ë¹„ìœ¨ë¡œ ì°¸ê³ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í•´ë‹¹ ì‹œì ì—ì„œ ì˜ˆì¸¡í•´ì•¼ í•  ë‹¨ì–´ì™€ ì—°ê´€ì´ ìˆëŠ” ì…ë ¥ ë‹¨ì–´ ë¶€ë¶„ì„ ì¢€ ë” ì§‘ì¤‘(attention)í•´ì„œ ë´„"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c9d34b8-a6bb-46ac-8961-98653aa7c413",
   "metadata": {},
   "source": [
    "## ì–´í…ì…˜ í•¨ìˆ˜(attention function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb3631-3491-46b6-b0ca-04661e1f6553",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_5.png' width='300'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e8191-c7a8-4ac8-8579-88af3be23018",
   "metadata": {},
   "source": [
    "**Attention(Q, K, V) = Attention Value**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef49345-540d-48c1-8d49-aacf0dda17e9",
   "metadata": {},
   "source": [
    "ì£¼ì–´ì§„ 'ì¿¼ë¦¬(Query)'ì— ëŒ€í•´ì„œ ëª¨ë“  'í‚¤(Key)'ì™€ì˜ ìœ ì‚¬ë„ë¥¼ ê°ê° êµ¬í•¨ \n",
    "- ì´ ìœ ì‚¬ë„ë¥¼ í‚¤ì™€ ë§µí•‘ë˜ì–´ìˆëŠ” ê°ê°ì˜ 'ê°’(Value)'ì— ë°˜ì˜\n",
    "- ìœ ì‚¬ë„ê°€ ë°˜ì˜ëœ 'ê°’(Value)'ì„ ëª¨ë‘ ë”í•´ì„œ ë¦¬í„´\n",
    "- ì–´í…ì…˜ ê°’(Attention Value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34da1a70-f6f0-4625-b853-ba25ab2e2d14",
   "metadata": {},
   "source": [
    "## ë‹·-í”„ë¡œë•íŠ¸ ì–´í…ì…˜(Dot-Product Attention)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af0575-d1c1-49d7-8f16-42b727d07d4f",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_6.png' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ba9f5-1b8a-4d94-a203-fe3203feee2c",
   "metadata": {},
   "source": [
    "ì˜ˆì‹œ)\n",
    "- ë””ì½”ë”ì˜ ì„¸ë²ˆì§¸ LSTM ì…€ì—ì„œ ì¶œë ¥ ë‹¨ì–´ë¥¼  ì˜ˆì¸¡. \n",
    "- ë””ì½”ë”ì˜ ì²«ë²ˆì§¸, ë‘ë²ˆì§¸ LSTM ì…€ì€ ì´ë¯¸ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ \"je\"ì™€ \"suis\"ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê³¼ì •ì„ ê±°ì³¤ë‹¤ê³  ê°€ì •\n",
    "- ì„¸ë²ˆì§¸ LSTM ì…€ì€ ì¶œë ¥ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ì„œ ì¸ì½”ë”ì˜ ëª¨ë“  ì…ë ¥ ë‹¨ì–´ë“¤ì˜ ì •ë³´ë¥¼ ë‹¤ì‹œ í•œë²ˆ ì°¸ê³ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2454b-545c-4335-ad01-f1c1c3e8d5cd",
   "metadata": {},
   "source": [
    "ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ í†µí•´ ë‚˜ì˜¨ ê²°ê³¼ê°’ì€ I, am, a, student ë‹¨ì–´ ê°ê°ì´ ì¶œë ¥ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•  ë•Œ ì–¼ë§ˆë‚˜ ë„ì›€ì´ ë˜ëŠ” ì§€ì˜ ì •ë„ë¥¼ ìˆ˜ì¹˜í™”í•œ ê°’\n",
    "\n",
    "- ==>  ì´ë¥¼ í•˜ë‚˜ì˜ ì •ë³´ë¡œ ë‹´ì•„ì„œ ë””ì½”ë”ë¡œ ì „ì†¡ (ë…¹ìƒ‰ ì‚¼ê°í˜•)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ec612-9d6a-4dea-9488-22459fa42279",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_7.png' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83266433-171b-43cd-a628-5c9fd629b94c",
   "metadata": {},
   "source": [
    "### ì–´í…ì…˜ ìŠ¤ì½”ì–´(attention score)\n",
    "\n",
    "í˜„ì¬ ë””ì½”ë”ì˜ ì‹œì  $t$ì—ì„œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´, ì¸ì½”ë”ì˜ ëª¨ë“  ì€ë‹‰ ìƒíƒœ ê°ê°ì´ ë””ì½”ë”ì˜ í˜„ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœ $s_t$ì™€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ë¥¼ íŒë‹¨í•˜ëŠ” ìŠ¤ì½”ì–´ê°’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67d1f7-cc94-468c-a22a-9e5dd3d59145",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_8.png' width='300'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b469dbf-bb10-443b-8122-3100363eed9b",
   "metadata": {},
   "source": [
    "- ë‹·-í”„ë¡œë•íŠ¸ ì–´í…ì…˜ì—ì„œëŠ” ìŠ¤ì½”ì–´ ê°’ì„ êµ¬í•˜ê¸° ìœ„í•´ $s_t$ë¥¼ ì „ì¹˜í•˜ê³  ê° ì€ë‹‰ ìƒíƒœì™€ ë‚´ì (dot product)ì„ ìˆ˜í–‰ \n",
    "- ì¦‰, ëª¨ë“  ì–´í…ì…˜ ìŠ¤ì½”ì–´ ê°’ì€ ìŠ¤ì¹¼ë¼ê°€ ë¨\n",
    "\n",
    "ì¸ì½”ë”ì˜ ëª¨ë“  ì€ë‹‰ ìƒíƒœì˜ ì–´í…ì…˜ ìŠ¤ì½”ì–´ì˜ ëª¨ìŒê°’ì„ $e^t$ë¼ê³  ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c6993-3db9-43fd-ae9c-ec8a83d2eca4",
   "metadata": {},
   "source": [
    "### ì–´í…ì…˜ ë¶„í¬(attention distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c8be9-6143-4b36-8cca-1e50eff9d5ce",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_9.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca27467-d047-45ef-ac0b-a080560a1d29",
   "metadata": {},
   "source": [
    "- $e^t$ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬, ëª¨ë“  ê°’ì„ í•©í•˜ë©´ 1ì´ ë˜ëŠ” í™•ë¥  ë¶„í¬ë¥¼ ì–»ìŒ\n",
    "- ê°ê°ì˜ ê°’ëŠ” ì–´í…ì…˜ ê°€ì¤‘ì¹˜ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f9949-8fca-4ee4-918b-d9e609495ac0",
   "metadata": {},
   "source": [
    "$\\alpha^t = softmax(e^t)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10a8433f-5950-4f09-8ccd-4455dc539ec9",
   "metadata": {},
   "source": [
    "### ì–´í…ì…˜ ê°’(attention value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad328fb-99c6-49e2-bc3a-f360ed427529",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_10.png' width='450'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3db20c-33b8-4379-854a-eaec05aecef6",
   "metadata": {},
   "source": [
    "ì–´í…ì…˜ì˜ ìµœì¢… ê²°ê³¼ê°’ì„ ì–»ê¸° ìœ„í•´ì„œ ê° ì¸ì½”ë”ì˜ ì€ë‹‰ ìƒíƒœì™€ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ê°’ë“¤ì„ ê³±í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ ëª¨ë‘ ë”í•¨\n",
    "- ì¦‰, ê°€ì¤‘í•©(Weighted Sum)ì„ ì§„í–‰\n",
    "\n",
    "ì´ëŸ¬í•œ ì–´í…ì…˜ ê°’ $a_t$ëŠ” ì¢…ì¢… ì¸ì½”ë”ì˜ ë¬¸ë§¥ì„ í¬í•¨í•˜ê³  ìˆë‹¤ê³  í•˜ì—¬, ì»¨í…ìŠ¤íŠ¸ ë²¡í„°(context vector)ë¼ê³ ë„ ë¶ˆë¦¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b740a89-312e-4783-894e-03f45001c23d",
   "metadata": {},
   "source": [
    "$a_t = \\sum^{N}_{i=1} \\alpha_i^{t}h_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf50c86-bda5-447e-830e-5348dd02f61a",
   "metadata": {},
   "source": [
    "### ì–´í…ì…˜ ê°’ê³¼ ë””ì½”ë” ì€ë‹‰ìƒíƒœ ì—°ê²°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5cf7fa-bffd-42d9-832b-139211330656",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_11.png' width='450'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350680b-4f87-49a1-8eec-2da4f20f7e34",
   "metadata": {},
   "source": [
    "ì–´í…ì…˜ ê°’ $a_t$ë¥¼ $s_t$ì™€ ê²°í•©(concatenate)í•˜ì—¬ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë§Œë“¦ => $v_t$\n",
    "\n",
    "- ì´ $v_t$ë¥¼ ì˜ˆì¸¡ ì—°ì‚°ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œì„œ ì¸ì½”ë”ë¡œë¶€í„° ì–»ì€ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë” ì˜ ì˜ˆì¸¡í•  ìˆ˜ ìˆê²Œ ë¨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40777fda-20c3-4b59-a90d-06a6ee332720",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_12.png' width='200'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25926f-5645-4ef8-a7bc-e266e3bc3d47",
   "metadata": {},
   "source": [
    "$\\tilde{s}_t=\\tanh(\\mathbf{W}_c[a_t;s_t]+b_c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797bbf4c-f72e-4b69-b614-164f1f2cb27d",
   "metadata": {},
   "source": [
    "- ë…¼ë¬¸ì—ì„œëŠ” $v_t$ë¥¼ ë°”ë¡œ ì¶œë ¥ì¸µìœ¼ë¡œ ë³´ë‚´ê¸° ì „ì— ì‹ ê²½ë§ ì—°ì‚°ì„ í•œ ë²ˆ ë” ì¶”ê°€ (ê°€ì¤‘ì¹˜ í–‰ë ¬ê³¼ ê³±í•˜ê³ , í¸í–¥ ì¶”ê°€, í•˜ì´í¼ë³¼ë¦­íƒ„ì  íŠ¸ í•¨ìˆ˜)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf7792-b812-4f8f-addd-eebfd70f19d8",
   "metadata": {},
   "source": [
    "$\\hat{y}_t = Softmax(\\mathbf{W}_y \\tilde{s}_t + b_y)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69bdee34-e77a-402e-909f-0ee60cc1eff8",
   "metadata": {},
   "source": [
    "- $\\tilde{s}_t$ë¥¼ ì¶œë ¥ì¸µì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ë²¡í„° ($\\hat{ğ‘¦}_ğ‘¡$)ë¥¼ ì–»ìŒ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef7c18-0af4-4947-863a-f3d3105fdebc",
   "metadata": {},
   "source": [
    "<img src='img/nlp_04_13.png' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81550e76-ffb2-4528-b635-be1f3b4b8b3a",
   "metadata": {},
   "source": [
    "## ë°”ë‹¤ë‚˜ìš° ì–´í…ì…˜(Bahdanau Attention)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32bf01e2-133e-4b9b-99fa-43db8b6014c3",
   "metadata": {},
   "source": [
    "ì–´í…ì…˜ ìŠ¤ì½”ì–´\n",
    "\n",
    "- ë°”ë‹¤ë‚˜ìš° ì–´í…ì…˜ì—ì„œëŠ” $t-1$ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœ $ğ‘ _{ğ‘¡âˆ’1}$ë¥¼ ì‚¬ìš©\r",
    "- $score(ğ‘ _{ğ‘¡âˆ’1},h_i) = W^T_a tanh(W_bs_{t-1}+W_ch_i)$, $score(ğ‘ _{ğ‘¡âˆ’1},H) = W^T_a tanh(W_bs_{t-1}+W_cH)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421e313-6c32-41f6-b71e-b6fde256a0b9",
   "metadata": {},
   "source": [
    "ì–´í…ì…˜ ë¶„í¬\n",
    "- ì†Œí”„íŠ¸ë§¥ìŠ¤ ì‚¬ìš©\n",
    "\n",
    "ì–´í…ì…˜ ê°’\n",
    "- ê°€ì¤‘í•©(Weighted Sum) ì§„í–‰ a.k.a. ì»¨í…ìŠ¤íŠ¸ ë²¡í„°\n",
    "\n",
    "ì–´í…ì…˜ ê°’(attention value)\n",
    "- ì»¨í…ìŠ¤íŠ¸ ë²¡í„°($a_t$)ì™€ í˜„ì¬ ì‹œì ì˜ ì…ë ¥ì¸ ë‹¨ì–´ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì—°ê²°í•˜ê³ , í˜„ì¬ ì‹œì ì˜ ìƒˆë¡œìš´ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
    "- ì´ì „ ì‹œì ì˜ ì…€ë¡œë¶€í„° ì „ë‹¬ë°›ì€ ì€ë‹‰ ìƒíƒœ $ğ‘ _{ğ‘¡âˆ’1}$ì™€ í˜„ì¬ ì‹œì ì˜ ìƒˆë¡œìš´ ì…ë ¥ìœ¼ë¡œë¶€í„° $ğ‘ _ğ‘¡$ë¥¼ êµ¬í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de890ce-a023-40e0-aed4-f9cea0255424",
   "metadata": {},
   "source": [
    "## ì‹¤ìŠµ ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b83b025-d137-4fc0-9c8c-d2af4dfbfbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vector shape: (64, 256)\n",
      "Attention weights shape: (64, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "import numpy as np\n",
    "\n",
    "class BahdanauAttention(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query: Decoder hidden state (batch_size, hidden size)\n",
    "        # values: Encoder output (batch_size, seq_len, hidden size)\n",
    "        \n",
    "        # Expand query to (batch_size, seq_len, hidden size)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        \n",
    "        # Score shape == (batch_size, seq_len, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "        \n",
    "        # Attention weights shape == (batch_size, seq_len, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # Context vector shape after sum == (batch_size, hidden size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "\n",
    "# ì˜ˆì‹œ ì…ë ¥ ë°ì´í„°\n",
    "encoder_output = np.random.rand(64, 10, 256).astype(np.float32)  # (batch_size, seq_len, hidden_size)\n",
    "decoder_hidden = np.random.rand(64, 256).astype(np.float32)      # (batch_size, hidden_size)\n",
    "\n",
    "# Bahdanau ì–´í…ì…˜ ë ˆì´ì–´ ìƒì„±\n",
    "attention_layer = BahdanauAttention(units=10)\n",
    "context_vector, attention_weights = attention_layer(decoder_hidden, encoder_output)\n",
    "\n",
    "print(\"Context vector shape:\", context_vector.shape)  # (batch_size, hidden_size)\n",
    "print(\"Attention weights shape:\", attention_weights.shape)  # (batch_size, seq_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2437b800-a543-409e-be53-2d4ed402db09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vector shape: torch.Size([64, 256])\n",
      "Attention weights shape: torch.Size([64, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, attn_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = nn.Linear(hidden_size, attn_size)\n",
    "        self.W2 = nn.Linear(hidden_size, attn_size)\n",
    "        self.V = nn.Linear(attn_size, 1)\n",
    "\n",
    "    def forward(self, query, values):\n",
    "        # query: (batch_size, hidden_size)\n",
    "        # values: (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        query_with_time_axis = query.unsqueeze(1)  # (batch_size, 1, hidden_size)\n",
    "        score = self.V(torch.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))  # (batch_size, seq_len, 1)\n",
    "        \n",
    "        attention_weights = F.softmax(score, dim=1)  # (batch_size, seq_len, 1)\n",
    "        \n",
    "        context_vector = attention_weights * values  # (batch_size, seq_len, hidden_size)\n",
    "        context_vector = torch.sum(context_vector, dim=1)  # (batch_size, hidden_size)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "\n",
    "# ì˜ˆì‹œ ì…ë ¥ ë°ì´í„°\n",
    "batch_size = 64\n",
    "seq_len = 10\n",
    "hidden_size = 256\n",
    "attn_size = 10\n",
    "\n",
    "encoder_output = torch.randn(batch_size, seq_len, hidden_size)  # (batch_size, seq_len, hidden_size)\n",
    "decoder_hidden = torch.randn(batch_size, hidden_size)  # (batch_size, hidden_size)\n",
    "\n",
    "# Bahdanau ì–´í…ì…˜ ë ˆì´ì–´ ìƒì„±\n",
    "attention_layer = BahdanauAttention(hidden_size, attn_size)\n",
    "context_vector, attention_weights = attention_layer(decoder_hidden, encoder_output)\n",
    "\n",
    "print(\"Context vector shape:\", context_vector.shape)  # (batch_size, hidden_size)\n",
    "print(\"Attention weights shape:\", attention_weights.shape)  # (batch_size, seq_len, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22d18eb-040d-4536-ab66-37bab1d66658",
   "metadata": {},
   "source": [
    "# ì°¸ê³ ìë£Œ\n",
    "\n",
    "- ë”¥ ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸(https://wikidocs.net/book/2155)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
