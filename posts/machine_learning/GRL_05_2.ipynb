{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f28461fd",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"그래프 머신러닝: (5-2) GNN: 일반화된 집계 및 업데이트\"\n",
    "subtitle: \"(GRL) GNN: Generalized Aggregation and Update\"\n",
    "author: \"Cheonghyo Cho\"\n",
    "categories: [graph, network, GNN, deep learning]\n",
    "image: \"grl_05_2.PNG\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9204a",
   "metadata": {},
   "source": [
    "Hamilton,W.L. *Graph Representation Learning*. 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab4d04",
   "metadata": {},
   "source": [
    "Basic GNN은 여러 가지 방법으로 개선되고 일반화될 수 있다. 여기서는 aggregation과 update 작업을 일반화하고 개선할 수 있는 방법에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b321c487",
   "metadata": {},
   "source": [
    "# Generalized Neighborhood Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510ca87-2659-423f-86b9-8945ccb0ead2",
   "metadata": {},
   "source": [
    "## Neighborhood Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab5a2c1-a520-4431-983d-6214d562f852",
   "metadata": {},
   "source": [
    "가장 기본적인 이웃 집계(aggreagation)는 단순히 이웃 임베딩의 합을 취하는 것이나, 이 방식은 불안정하고 노드 degree에 매우 민감할 수 있다. 예를 들어, 노드 $u$가 노드 $u'$보다 $100$배 많은 이웃(즉, 훨씬 더 높은 차수)이 있다고 가정 할 때 $\\left\\| \\sum_{v \\in \\mathcal{N}(u)} h_v \\right\\| \\gg \\left\\| \\sum_{v' \\in \\mathcal{N}(u')} h_{v'} \\right\\|$라고 합리적으로 기대할 수 있다. 이러한 급격한 크기 차이로 인해 수치적 불안정성과 최적화의 어려움이 발생할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0bca98-1685-4bc7-a1bd-75c60523e313",
   "metadata": {},
   "source": [
    "해결 방법으로 관련된 포함된 노드 degree에 따라 집계를 단순히 정규화하는 방법이 있다.\n",
    "\n",
    "- 가장 단순한 방법은 합 대신 평균화 하는 것이다:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11514b0-0ed7-415a-9790-e55a103fdad9",
   "metadata": {},
   "source": [
    "$$ \\mathbf{m}_{\\mathcal{N}(u)} = \\frac{\\sum_{v \\in \\mathcal{N}(u)} \\mathbf{h}_v}{|\\mathcal{N}(u)|} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415c633-440d-4041-beb2-053de220594f",
   "metadata": {},
   "source": [
    "- Kipf and Welling [2016a]에서 사용된 다음과 같은 *대칭 정규화*(*symmetric normalization*)와 같은 다른 정규화 factor도 있다:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f81fa7-211f-4b58-9af2-5f5ee7f47629",
   "metadata": {},
   "source": [
    "$$ \\mathbf{m}_{\\mathcal{N}(u)} = \\sum_{v \\in \\mathcal{N}(u)} \\frac{\\mathbf{h}_v}{\\sqrt{|\\mathcal{N}(u)| |\\mathcal{N}(v)|}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012ab0c-9719-49e2-98e7-a170eaa06815",
   "metadata": {},
   "source": [
    "특히, 대칭 정규화 집계와 기본 GNN 업데이트 함수를 결합하면 spectral graph convolution의 1차(first-order) 근사(approximation)가 생성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227536e-6238-4283-b647-47fc2da110e9",
   "metadata": {},
   "source": [
    "**Graph Convolutional Networks (GCNs)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c3fd63-65d8-4158-af47-fdc3b06e1043",
   "metadata": {},
   "source": [
    "가장 널리 사용되는 기준이 되는 그래프 신경망 모델 중 하나인 그래프 컨볼루션 네트워크(**GCN**)는 대칭 정규화 집계와 self-loop 업데이트 접근 방식을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c13fdf-9dfe-4060-ad13-48145e343bf9",
   "metadata": {},
   "source": [
    "GCN은 메시지 전달 함수를 다음과 같이 정의한다:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4732b283-1765-412b-8c95-95950b096077",
   "metadata": {},
   "source": [
    "$$\\mathbf{h}^{(k)}_u = \\sigma \\left( \\mathbf{W}^{(k)} \\sum_{v \\in \\mathcal{N}(u) \\cup \\{u\\}} \\frac{\\mathbf{h}_v}{\\sqrt{|\\mathcal{N}(u)| |\\mathcal{N}(v)|}} \\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec6e5e-82a7-4d6a-b195-b4b7b3d2f694",
   "metadata": {},
   "source": [
    "정규화는 필요할까?\n",
    "\n",
    "- GNN을 사용할 때 안정적이고 강력한 성능을 얻으려면 적절한 정규화가 필수적일 수 있으나, 정규화로 인해 정보가 손실될 수도 있다는 점에 유의해야 한다.\n",
    "- 예를 들어, 정규화 후에는 학습된 임베딩을 사용하여 서로 다른 degree의 노드를 구별하는 것이 어렵거나 불가능할 수 있으며, 다양한 다른 구조 그래프 특징이 정규화에 의해 가려질 수 있다.\n",
    "- 일반적으로 정규화는 노드 피쳐 정보가 구조적 정보보다 훨씬 더 유용하거나, 최적화 중에 불안정을 초래할 수 있는 노드 degree 범위가 매우 넓은 작업에서 유용하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a3339-5a5f-4a28-9303-473173d698ee",
   "metadata": {},
   "source": [
    "## Set Aggregators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2791ad-020f-448b-b194-a9fc5d444d95",
   "metadata": {},
   "source": [
    "이웃 집계 연산은 기본적으로 집합 함수(set function)이다. 이웃 임베딩 집합 {$\\mathbf{h}_v, \\forall v \\in \\mathcal{N}(u)$}이 주어지고, 이를 싱글 벡터 $\\mathbf{m}_{\\mathcal{N}(u)}$에 매핑해야 한다. {$\\mathbf{h}_v, \\forall v \\in \\mathcal{N}(u)$}이 집합이라는 사실은 실제로 매우 중요하다: 노드 이웃에는 자연적인 순서가 없으며, 따라서 정의하는 모든 집계 함수는 *순열 불변*(*permutation invariant*)이어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09b73f-4c79-4d75-ac0a-57c96a2b6309",
   "metadata": {},
   "source": [
    "집계 함수를 정의하는 한 가지 원칙적인 접근 방식은 순열 불변 신경망 이론(permutaion invariant neural network)을 기반으로 한다. \n",
    "\n",
    "예를 들어, Zaheer et al. [2017]은 다음 형식의 집계 함수가 범용적 집합 함수 근사기(*universal set function approximator*)임을 보여준다:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af0173-7bb9-41cc-a656-2e477e3cf179",
   "metadata": {},
   "source": [
    "$$\\mathbf{m}_{\\mathcal{N}(u)} = MLP_{\\theta} \\left( \\sum_{v \\in \\mathcal{N}(u)} MLP_{\\phi} (\\mathbf{h}_v) \\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12b412-79e4-4d31-8489-0ee0e87f0211",
   "metadata": {},
   "source": [
    "## Message Passing with Self-Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef2bc9-d638-4b88-9a99-7ea2f699fb3d",
   "metadata": {},
   "source": [
    "neural message passing 접근 방식을 단순화하기 위해 입력 그래프에 self-loop를 추가하고 명시적 업데이트 단계를 생략하는 것이 일반적이다. 따라서 message passing을 단순히 다음과 같이 정의한다:\n",
    "\n",
    "$$h_u^{(k)} = \\text{AGGREGATE}\\left(\\left\\{ h_v^{(k-1)}, \\forall v \\in \\mathcal{N}(u) \\cup \\{u\\} \\right\\}\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052f195-5166-4c29-b3ef-6f4b54636c5d",
   "metadata": {},
   "source": [
    "$\\mathcal{N}(u) \\cup \\{u\\}$ 집합 대상으로 aggregate하겠다는 것은 노드의 이웃뿐아니라 자기 자신도 포함한다는 것이다.\n",
    "\n",
    "이 방법의 장점은 업데이트가 aggregation 방법을 통해 암시적으로 정의되기 때문에 더 이상 명시적 업데이트 함수를 정의할 필요가 없다는 것이다. 이러한 방식으로 전달되는 메시지를 단순화하면 종종 과적합을 완화할 수 있지만 노드의 이웃에서 오는 정보를 노드 자체의 정보와 구별할 수 없기 때문에 GNN의 표현성을 제한하기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02ceb35-ccf4-4a6e-8999-f5557656bb2a",
   "metadata": {},
   "source": [
    "Basic GNN의 경우, self-loops를 추가하는 것은 $\\mathbf{W}_{self}$ 행렬과 $\\mathbf{W}_{neigh}$ 행렬 간에 매개변수를 공유하는 것과 동일하며, 다음과 같은 graph-level 업데이트를 제공한다.\n",
    "\n",
    "$$\\mathbf{H}^{(t)} = \\sigma \\left( (\\mathbf{A} + \\mathbf{I})\\mathbf{H}^{(t-1)}\\mathbf{W}^{(t)} \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77656f6-b956-4b75-bbb3-9763b8801cc5",
   "metadata": {},
   "source": [
    "다음 포스트에서는 `AGGREGATE`, `UPDATE` 함수에 대해 더 알아보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86bc83",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "\n",
    "[1] Hamilton, W. L. (2020). *Graph Representation Learning.* Morgan & Claypool Publishers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
