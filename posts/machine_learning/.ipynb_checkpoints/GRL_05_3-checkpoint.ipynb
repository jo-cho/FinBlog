{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f28461fd",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"그래프 머신러닝: (5-3) GNN: 다양한 그래프\"\n",
    "subtitle: \"(GRL) GNN: Graphs\"\n",
    "author: \"Cheonghyo Cho\"\n",
    "categories: [graph, network, GNN, deep learning]\n",
    "image: \"grl_05_3.PNG\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9204a",
   "metadata": {},
   "source": [
    "Hamilton,W.L. *Graph Representation Learning*. 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab4d04",
   "metadata": {},
   "source": [
    "지금까지는 심플 그래프에서의 GNN을 가정했으나, 그래프가 다중관계이거나 hetrogenous(예: 지식 그래프)할 때를 다루지 못했다. 이러한 그래프를 다루는 몇 가지 전략을 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b321c487",
   "metadata": {},
   "source": [
    "# Edge features and Multi-relational GNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510ca87-2659-423f-86b9-8945ccb0ead2",
   "metadata": {},
   "source": [
    "## Relational Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cea280-14b1-4d8a-ac83-8c58034a637f",
   "metadata": {},
   "source": [
    "Relational GNN 중 Relational Graph Convolutional Network(RGCN)[Schlichtkrull et al., 2017] 방법이 대표적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab5a2c1-a520-4431-983d-6214d562f852",
   "metadata": {},
   "source": [
    "이 방법은 관계 유형별로 별도의 변환 행렬을 지정하여 여러 관계 유형을 수용하도록 집계(aggregation) 함수를 보강한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54c763f-41cc-4244-b07b-e190b9ca8b5b",
   "metadata": {},
   "source": [
    "$$\\mathbf{m}_{\\mathcal{N}(u)} = \\sum_{\\tau \\in \\mathcal{R}} \\sum_{v \\in \\mathcal{N}_{\\tau}(u)} \\frac{\\mathbf{W}_{\\tau} \\mathbf{h}_v}{f_n(\\mathcal{N}(u), \\mathcal{N}(v))},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40832e3d-0a2a-4efb-bcca-626bd8f826d9",
   "metadata": {},
   "source": [
    "여기서, $f_n$은 노드 $u$의 이웃과 집계되는 이웃 $v$에 모두 의존하는 정규화 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012ab0c-9719-49e2-98e7-a170eaa06815",
   "metadata": {},
   "source": [
    "전반적으로 RGCN의 다중 관계형 집계는 정규화를 사용하는 기본 GNN 접근 방식과 유사하지만 서로 다른 엣지 유형에 따라 정보를 별도로 집계한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227536e-6238-4283-b647-47fc2da110e9",
   "metadata": {},
   "source": [
    "**Parameter Sharing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c3fd63-65d8-4158-af47-fdc3b06e1043",
   "metadata": {},
   "source": [
    "Naive한 RGCN의 단점으로는 관계 유형당 trainable matrix가 있기 때문에 파라미터 수가 매우 크다는 것이다. Schlichtkrull et al.[2017]은 따라서 basis 행렬들을 이용한 parameter sharing을 제안하였다:\n",
    "\n",
    "$$\\mathbf{W}_{\\tau} = \\sum_{i=1}^{b} \\alpha_{i,\\tau} \\mathbf{B}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ddd98-2624-45d2-bb55-3529887fdcde",
   "metadata": {},
   "source": [
    "이러한 방식에서 모든 관계 행렬은 basis 행렬 $\\mathbf{B}_1, \\dots, \\mathbf{B}_b$의 선형 조합이 되고, 관계와 관련된 파라미터는 각 관계 $\\tau$에 대한 $b$개의 조합 가중 $\\alpha_{1,\\tau}, \\dots, \\alpha_{b,\\tau}$이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c13fdf-9dfe-4060-ad13-48145e343bf9",
   "metadata": {},
   "source": [
    "Basis sharing 방식에서 집계 함수를 다음과 같이 정의한다:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad6d11-2456-49d9-b4eb-dad2d06c68b5",
   "metadata": {},
   "source": [
    "$$\\mathbf{m}_{\\mathcal{N}(u)} = \\sum_{\\tau \\in \\mathcal{R}} \\sum_{v \\in \\mathcal{N}_{\\tau}(u)} \\frac{\\alpha_{\\tau} \\times_1 \\mathbf{B} \\times_2 \\mathbf{h}_v}{f_n(\\mathcal{N}(u), \\mathcal{N}(v))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a3339-5a5f-4a28-9303-473173d698ee",
   "metadata": {},
   "source": [
    "## Attention and Feature Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2791ad-020f-448b-b194-a9fc5d444d95",
   "metadata": {},
   "source": [
    "관계별로 별도의 집계 파라미터를 정의하는 관계형 GNN 접근 방식은 다중 관계형 그래프 및 개별 edge feature가 있는 경우에 적용할 수 있다. 일반적인 형태의 edge feature가 있는 경우를 수용하기 위해 이러한 feature을 활용하거나 메시지 패싱 중에 이 정보를 인접 임베딩과 연결(concatenate)하여 활용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dc4a2b-a397-4c51-9450-397c1fc7b9f7",
   "metadata": {},
   "source": [
    "예를 들어 기본 집계가 주어지면 edge feature를 leverage해 다음과 같은 새로운 집계 함수를 정의할 수 있다:\n",
    "\n",
    "$$\\mathbf{m}_{\\mathcal{N}(u)} = \\text{AGGREGATE}_{\\text{base}}(\\{\\mathbf{h}_v \\oplus \\mathbf{e}_{(u,\\tau,v)}, \\forall v \\in \\mathcal{N}(u)\\})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2fb8f-8f12-4a9e-865f-043b66e09ab8",
   "metadata": {},
   "source": [
    "$\\mathbf{e}_{(u,\\tau,v)}$는 엣지 $(u,\\tau,v)$에 대한 임의의 vector-valued feature이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8b519-01a6-4327-9801-9fd13fc675f3",
   "metadata": {},
   "source": [
    "# Graph Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f8744-b2b8-494f-9d10-f8c04ca74c24",
   "metadata": {},
   "source": [
    "신경망 메시지 전달로 그래프 수준에서 예측하는 방법을 알아보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739dc30-8520-4153-8969-abd1bcf76ece",
   "metadata": {},
   "source": [
    "노드 임베딩 집합 $\\{\\mathbf{z}_1, \\dots , \\mathbf{z}_{|V|} \\}$를 전체 그래프를 나타내는 임베딩 $\\mathbf{z}_\\mathcal{G}$에 매핑하는 풀링 함수 $f_p$를 설계한다. 이웃 임베딩 세트를 학습하기 위해 논의된 모든 방법은 그래프 수준 풀링에 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e03f3-c24d-4888-a6c7-de4557e18413",
   "metadata": {},
   "source": [
    "실제로 집합 풀링을 통해 그래프 수준 임베딩을 학습하는 데 가장 일반적으로 적용되는 두 가지 방법이 있다. 첫 번째는 단순히 노드 임베딩의 합계(또는 평균)를 취하는 것이다:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce582f9b-bf33-4801-ab55-a4e32e0bc3a7",
   "metadata": {},
   "source": [
    "$$\\mathbf{z}_G = \\frac{\\sum_{v \\in \\mathcal{V}} \\mathbf{z}_c}{f_n(|\\mathcal{V}|)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a5e230-eabe-402b-bf82-d687fe817da2",
   "metadata": {},
   "source": [
    "두 번째는 LSTM과 attention을 조합하여 노드 임베딩을 풀링하는 방법이다. $t=1,...,T$ 단계에 대해 반복되는 방정식의 집합으로 정의된 일련의 attention 기반 집계를 반복한다:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f75ea0-1f51-485b-8ec7-48a0fce9c3c0",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\r\n",
    "\\mathbf{q}_t &= \\text{LSTM}(\\mathbf{o}_{t-1}, \\mathbf{q}_{t-1}), \\\\\r\n",
    "e_{v,t} &= f_a(\\mathbf{z}_v, \\mathbf{q}_t), \\quad \\forall v \\in \\mathcal{V}, \\\\\r\n",
    "a_{v,t} &= \\frac{\\exp(e_{v,i})}{\\sum_{u \\in \\mathcal{V}} \\exp(e_{u,t})}, \\quad \\forall v \\in \\mathcal{V}, \\\\\r\n",
    "\\mathbf{o}_t &= \\sum_{v \\in \\mathcal{V}} a_{v,t} \\mathbf{z}_v.\r\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb58026-05cc-462e-8880-4f393a4b366e",
   "metadata": {},
   "source": [
    "여기서, $\\mathbf{q}_t$는 각 반복에서 attention에 대한 쿼리 벡터이다. 이 쿼리 벡터는 각 노드에 대해 attention score를 계산하기 위해 사용된다($f_a$는 어텐션 함수). \n",
    "\n",
    "정규화된 attention score $a_{v,t}$는 노드 임베딩에 대한 가중치 역할을 하여 가중합을 계산한다.\n",
    "\n",
    "마지막으로 $T$번의 반복을 통해 전체 그래프에 대한 임베딩을 계산한다:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26995d4-4348-4bb8-b2f8-f111dab670c4",
   "metadata": {},
   "source": [
    "$$\\mathbf{z}_G = \\mathbf{o}_1 \\oplus \\mathbf{o}_2 \\oplus \\ldots \\oplus \\mathbf{o}_T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ff11e-61b4-4f08-bfa9-64528b833056",
   "metadata": {},
   "source": [
    "이 방법은 집합에 대한 어텐션 기반 풀링을 위한 정교한 아키텍처를 나타내며 많은 그래프 수준 분류 작업에서 널리 사용되는 풀링 방법이 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54f757-3677-40c8-9eca-dbacaf03b7da",
   "metadata": {},
   "source": [
    "**Graph Coarsening Approaches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33a734b-08a2-4dd2-8734-35c4bb4ac169",
   "metadata": {},
   "source": [
    "집합 풀링 방법의 한계점은 그래프의 구조를 이용하지 않는다는 것이다. 이에 따라 노드 표현을 풀링하는 수단으로 그래프 clustering 혹은 coarsening을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b560727-e40b-4d65-9bc0-e107b4b5cdd1",
   "metadata": {},
   "source": [
    "$$f_c \\rightarrow \\mathcal{G} \\times \\mathbb{R}^{|\\mathcal{V}| \\times d} \\rightarrow \\mathbb{R}^{+|\\mathcal{V}| \\times c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd58dfa-1bb0-4950-bf3c-2a58bba7e911",
   "metadata": {},
   "source": [
    "이 클러스터링 함수는 그래프의 모든 노드를 $c$개 클러스터에 할당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00c53d-631d-4df2-abff-d864c5b00ff4",
   "metadata": {},
   "source": [
    "이러한 매핑의 결과물을 $\\mathbf{S} = f_c(\\mathcal{G},\\mathbf{Z})$라고 하고, 이를 사용해 그래프를 coarsen한다. 구체적으로는 인접행렬과 노드 피쳐 집합을 새로 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07638e24-c57b-4acb-91e8-8df256a423ba",
   "metadata": {},
   "source": [
    "$$\\mathbf{A}^{\\text{new}} = \\mathbf{S}^{\\top} \\mathbf{A} \\mathbf{S} \\in \\mathbb{R}^{+c \\times c}$$\n",
    "\n",
    "$$\\mathbf{X}^{\\text{new}} = \\mathbf{S}^{\\top} \\mathbf{X} \\in \\mathbb{R}^{c \\times d}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a163a84-21c3-42a2-bd6d-7ff7e13f4eee",
   "metadata": {},
   "source": [
    "이 coarsening 방식은 CNN에서 사용되는 풀링 접근 방식에서 영감을 받았으며 입력 그래프의 다양한 granularity에서 작동하는 hierarchical GNN을 구축할 수 있다는 직관에 의존한다. 실제로 이러한 방식은 강력한 성능으로 이어질 수 있지만 불안정하고 훈련하기 어려울 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246ba69-8ba7-487a-b594-9285eb29461d",
   "metadata": {},
   "source": [
    "# Generalized Message Passing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c011d-681a-452f-8ca5-103a540e77a1",
   "metadata": {},
   "source": [
    "GNN 메시지 패싱 방법을 일반화하여 메시지 패싱의 각 단계에서 엣지 및 그래프 수준 정보를 활용할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2513314-df8e-459b-9431-6418b67d9bbf",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "\\mathbf{h}^{(k)}_{(u,v)} &= \\text{UPDATE}_{\\text{edge}} \\left( \\mathbf{h}^{(k-1)}_{(u,v)}, \\mathbf{h}^{(k-1)}_u, \\mathbf{h}^{(k-1)}_v, \\mathbf{h}^{(k-1)}_\\mathcal{G} \\right) \\\\\n",
    "\\mathbf{m}_{\\mathcal{N}(u)} &= \\text{AGGREGATE}_{\\text{node}} \\left( \\left\\{ \\mathbf{h}^{(k)}_{(u,v)} \\forall v \\in \\mathcal{N}(u) \\right\\} \\right) \\\\\n",
    "\\mathbf{h}^{(k)}_u &= \\text{UPDATE}_{\\text{node}} \\left( \\mathbf{h}^{(k-1)}_u, \\mathbf{m}_{\\mathcal{N}(u)}, \\mathbf{h}^{(k-1)}_\\mathcal{G} \\right) \\\\\n",
    "\\mathbf{h}^{(k)}_\\mathcal{G} &= \\text{UPDATE}_{\\text{graph}} \\left( \\mathbf{h}^{(k-1)}_\\mathcal{G}, \\left\\{ \\mathbf{h}^{(k)}_u  \\forall u \\in \\mathcal{V} \\right\\}, \\left\\{ \\mathbf{h}^{(k)}_{(u,v)} \\forall (u,v) \\in \\mathcal{E} \\right\\} \\right)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb2b28-1c2d-4408-9ea0-fe677a78bfc0",
   "metadata": {},
   "source": [
    "- 이 일반화된 메시지 패싱 프레임워크의 메시지 전달 작업과 관련하여 먼저 인시던트 노드의 임베딩을 기반으로 엣지 임베딩을 업데이트한다. \n",
    "\n",
    "- 다음으로, 모든 인시던트 엣지에 대한 엣지 임베딩을 집계하여 노드 임베딩을 업데이트한다. \n",
    "\n",
    "- 그래프 임베딩은 노드 및 엣지 표현 모두에 대한 업데이트 방정식에 사용되며, 그래프 수준 임베딩 자체는 각 반복이 끝날 때 모든 노드 및 엣지 임베딩을 집계하여 업데이트된다). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86bc83",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "\n",
    "[1] Hamilton, W. L. (2020). *Graph Representation Learning.* Morgan & Claypool Publishers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
